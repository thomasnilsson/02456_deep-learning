{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['je saigne gravement .', 'i m bleeding badly .']\n"
     ]
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('translation-data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French:\n",
      "tensor([145,  25,  66, 410,   5,   1])\n",
      "['c', 'est', 'un', 'bigot', '.', 'EOS']\n",
      "------------------------------\n",
      "English:\n",
      "tensor([ 14,  15,  42, 235,   4,   1])\n",
      "['he', 's', 'a', 'bigot', '.', 'EOS']\n",
      "\n",
      "French:\n",
      "tensor([ 348, 1220, 3633,  689,    5,    1])\n",
      "['ils', 'vont', 'torturer', 'tom', '.', 'EOS']\n",
      "------------------------------\n",
      "English:\n",
      "tensor([ 221,   78,   61,  532, 2252,  378,    4,    1])\n",
      "['they', 're', 'going', 'to', 'torture', 'tom', '.', 'EOS']\n",
      "\n",
      "French:\n",
      "tensor([ 123,  124,   34,  101, 2727,  241, 3767,    5,    1])\n",
      "['nous', 'avons', 'fini', 'de', 'repondre', 'aux', 'questions', '.', 'EOS']\n",
      "------------------------------\n",
      "English:\n",
      "tensor([  77,   78,   22, 1613, 2347,    4,    1])\n",
      "['we', 're', 'done', 'answering', 'questions', '.', 'EOS']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show example pair embedded\n",
    "for x in training_pairs[:3]:\n",
    "    french_sent = x[0].flatten()\n",
    "    english_sent = x[1].flatten()\n",
    "    \n",
    "    print(\"French:\")\n",
    "    print(french_sent)\n",
    "    print([input_lang.index2word[i.item()] for i in french_sent])\n",
    "    print(\"-\"*30)\n",
    "    print(\"English:\")\n",
    "    print(english_sent)\n",
    "    print([output_lang.index2word[i.item()] for i in english_sent])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAtiPeVk2UT8"
   },
   "source": [
    "### Define the model\n",
    "In this tutorial, we train `nn.TransformerEncoder` model on a language modeling task. The language modeling task is to assign a probability for the likelihood of a given word (or a sequence of words) to follow a sequence of words. \n",
    "\n",
    "A sequence of tokens are passed to the embedding layer first, followed by a positional encoding layer to account for the order of the word (see the next paragraph for more details). \n",
    "\n",
    "The nn.TransformerEncoder consists of multiple layers of `nn.TransformerEncoderLayer`. Along with the input sequence, a square attention mask is required because the self-attention layers in `nn.TransformerEncoder` are only allowed to attend the earlier positions in the sequence. For the language modeling task, any tokens on the future positions should be masked. \n",
    "\n",
    "To have the actual words, the output of `nn.TransformerEncoder` model is sent to the final Linear layer, which is followed by a log-Softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c7hJ6J3T2UT9",
    "outputId": "8ef26d82-506f-4a18-ddf2-3f0dab7eda1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "Z7-rsUqn2UUB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, src_lang_size, target_lang_size, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(src_lang_size, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, target_lang_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        #output = output.argmax(dim=2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPUNYXCH2UUD"
   },
   "source": [
    "### Positional Encoding\n",
    "`PositionalEncoding` module injects some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension as the embeddings so that the two can be summed. Here, we use sine and cosine functions of different frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "phW8WAXu2UUE"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-icIyOx2UUG"
   },
   "source": [
    "### Load and batch data\n",
    "The training process uses Wikitext-2 dataset from `torchtext`. The vocab object is built based on the train dataset and is used to numericalize tokens into tensors. \n",
    "\n",
    "Starting from sequential data, the `batchify()` function arranges the dataset into columns, trimming off any tokens remaining after the data has been divided into batches of size `batch_size`. \n",
    "\n",
    "For instance, with the alphabet as the sequence (total length of 26) and a batch size of 4, we would divide the alphabet into 4 sequences of length 6.\n",
    "\n",
    "These columns are treated as independent by the model, which means that the dependence of G and F can not be learned, but allows more efficient batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HoT-Yyrb3xkg",
    "outputId": "2c7b334f-2311-40cc-e723-2077c8cd5f1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Be7LKsEE2UUL"
   },
   "source": [
    "### Initiate an instance\n",
    "The model is set up with the hyperparameter below. The vocab size is equal to the length of the vocab object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngUHMofX2UUM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Embedding(4345, 200)\n",
       "  (decoder): Linear(in_features=200, out_features=2803, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_lang_size = input_lang.n_words # the size of the french vocab\n",
    "target_lang_size = output_lang.n_words # the size of the english vocab\n",
    "\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(src_lang_size, target_lang_size, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5XD8lgd2UUO"
   },
   "source": [
    "### Run the model\n",
    "`CrossEntropyLoss` is applied to track the loss and SGD implements stochastic gradient descent method as the optimizer. The initial learning rate is set to 5.0. StepLR is applied to adjust the learn rate through epochs. During the training, we use nn.utils.clip_grad_norm_ function to scale all the gradient together to prevent exploding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3119, -3.3002,  1.3234,  ..., -8.0747,  3.2964, -0.7686]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x, test_y = training_pairs[0]\n",
    "out = model.forward(test_x)\n",
    "out.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected target size (6, 2803), got torch.Size([6, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-a5219c0b07b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 1834\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   1835\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (6, 2803), got torch.Size([6, 1])"
     ]
    }
   ],
   "source": [
    "criterion(out, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3818, 0.3180, 1.1355],\n",
      "        [0.5823, 0.4457, 0.1678],\n",
      "        [0.4351, 0.6102, 1.2674],\n",
      "        [1.3871, 0.9824, 0.4858],\n",
      "        [0.1288, 0.9224, 1.0233],\n",
      "        [1.1999, 1.8882, 0.9079],\n",
      "        [0.4688, 1.1591, 1.2756],\n",
      "        [2.2619, 0.4256, 1.3807],\n",
      "        [1.6341, 0.3187, 0.3346],\n",
      "        [1.0537, 0.5703, 0.1285]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tnni/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/tnni/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3)\n",
    "output = F.sigmoid(x)\n",
    "target = torch.Tensor(10, 3).random_(2)\n",
    "\n",
    "criterion = nn.BCELoss(reduce=False)\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3]), torch.Size([10, 3]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjiKe4HL2UUO"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    n_pairs = len(training_pairs)\n",
    "    \n",
    "    #for batch, i in enumerate(range(0, n_pairs - 1)):\n",
    "    for i, (src, tar) in enumerate(training_pairs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Run source sentence through translator\n",
    "        output = model(src)\n",
    "        #output = output.view(-1, target_lang_size)\n",
    "        \n",
    "        print(output.shape, tar.shape)\n",
    "        # Calculate loss and perform backprop\n",
    "        loss = criterion(output, tar)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add to total loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i%200 == 0:\n",
    "            print(\"Epoch: %i, Loss: %i\" % (epoch, loss))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_model, val_pairs):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tar in val_pairs:\n",
    "            output = eval_model(data)\n",
    "            #output_flat = output.view(-1, target_lang_size)\n",
    "            total_loss += len(src) * criterion(output_flat, targets).item()\n",
    "    return total_loss / len(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 2803]) torch.Size([6, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (6, 2803), got torch.Size([6, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-2ff92bc3fa52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#epoch_start_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-b9393cd91216>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Calculate loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 1834\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   1835\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (6, 2803), got torch.Size([6, 1])"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    #epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "Qba1ne6H2UUR",
    "outputId": "e2dff930-da77-40c0-d11e-dbea34aa5d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 3195 batches | lr 5.00 | ms/batch 40.03 | loss  2.12 | ppl     8.29\n",
      "| epoch   1 |   400/ 3195 batches | lr 5.00 | ms/batch 39.14 | loss  2.06 | ppl     7.82\n",
      "| epoch   1 |   600/ 3195 batches | lr 5.00 | ms/batch 39.28 | loss  1.95 | ppl     7.03\n",
      "| epoch   1 |   800/ 3195 batches | lr 5.00 | ms/batch 39.43 | loss  2.01 | ppl     7.45\n",
      "| epoch   1 |  1000/ 3195 batches | lr 5.00 | ms/batch 39.24 | loss  1.91 | ppl     6.77\n",
      "| epoch   1 |  1200/ 3195 batches | lr 5.00 | ms/batch 39.37 | loss  1.92 | ppl     6.80\n",
      "| epoch   1 |  1400/ 3195 batches | lr 5.00 | ms/batch 39.12 | loss  1.92 | ppl     6.83\n",
      "| epoch   1 |  1600/ 3195 batches | lr 5.00 | ms/batch 39.30 | loss  1.94 | ppl     6.94\n",
      "| epoch   1 |  1800/ 3195 batches | lr 5.00 | ms/batch 39.26 | loss  1.93 | ppl     6.91\n",
      "| epoch   1 |  2000/ 3195 batches | lr 5.00 | ms/batch 39.24 | loss  1.94 | ppl     6.97\n",
      "| epoch   1 |  2200/ 3195 batches | lr 5.00 | ms/batch 39.09 | loss  1.93 | ppl     6.87\n",
      "| epoch   1 |  2400/ 3195 batches | lr 5.00 | ms/batch 39.20 | loss  1.94 | ppl     6.99\n",
      "| epoch   1 |  2600/ 3195 batches | lr 5.00 | ms/batch 39.20 | loss  1.95 | ppl     7.02\n",
      "| epoch   1 |  2800/ 3195 batches | lr 5.00 | ms/batch 39.14 | loss  1.98 | ppl     7.23\n",
      "| epoch   1 |  3000/ 3195 batches | lr 5.00 | ms/batch 39.22 | loss  1.86 | ppl     6.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 130.45s | valid loss  0.99 | valid ppl     2.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 3195 batches | lr 4.75 | ms/batch 39.44 | loss  1.81 | ppl     6.11\n",
      "| epoch   2 |   400/ 3195 batches | lr 4.75 | ms/batch 39.02 | loss  1.82 | ppl     6.15\n",
      "| epoch   2 |   600/ 3195 batches | lr 4.75 | ms/batch 39.23 | loss  1.75 | ppl     5.77\n",
      "| epoch   2 |   800/ 3195 batches | lr 4.75 | ms/batch 39.08 | loss  1.73 | ppl     5.63\n",
      "| epoch   2 |  1000/ 3195 batches | lr 4.75 | ms/batch 39.24 | loss  1.76 | ppl     5.81\n",
      "| epoch   2 |  1200/ 3195 batches | lr 4.75 | ms/batch 39.12 | loss  1.73 | ppl     5.62\n",
      "| epoch   2 |  1400/ 3195 batches | lr 4.75 | ms/batch 39.39 | loss  1.70 | ppl     5.46\n",
      "| epoch   2 |  1600/ 3195 batches | lr 4.75 | ms/batch 39.09 | loss  1.67 | ppl     5.32\n",
      "| epoch   2 |  1800/ 3195 batches | lr 4.75 | ms/batch 39.19 | loss  1.67 | ppl     5.30\n",
      "| epoch   2 |  2000/ 3195 batches | lr 4.75 | ms/batch 39.14 | loss  1.77 | ppl     5.86\n",
      "| epoch   2 |  2200/ 3195 batches | lr 4.75 | ms/batch 39.21 | loss  1.86 | ppl     6.40\n",
      "| epoch   2 |  2400/ 3195 batches | lr 4.75 | ms/batch 39.20 | loss  1.79 | ppl     5.97\n",
      "| epoch   2 |  2600/ 3195 batches | lr 4.75 | ms/batch 39.21 | loss  1.85 | ppl     6.38\n",
      "| epoch   2 |  2800/ 3195 batches | lr 4.75 | ms/batch 39.23 | loss  1.77 | ppl     5.88\n",
      "| epoch   2 |  3000/ 3195 batches | lr 4.75 | ms/batch 39.17 | loss  1.76 | ppl     5.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 130.24s | valid loss  1.02 | valid ppl     2.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 3195 batches | lr 4.51 | ms/batch 39.42 | loss  1.66 | ppl     5.28\n",
      "| epoch   3 |   400/ 3195 batches | lr 4.51 | ms/batch 39.20 | loss  1.60 | ppl     4.93\n",
      "| epoch   3 |   600/ 3195 batches | lr 4.51 | ms/batch 39.18 | loss  1.61 | ppl     4.98\n",
      "| epoch   3 |   800/ 3195 batches | lr 4.51 | ms/batch 39.17 | loss  1.61 | ppl     5.01\n",
      "| epoch   3 |  1000/ 3195 batches | lr 4.51 | ms/batch 39.13 | loss  1.61 | ppl     5.00\n",
      "| epoch   3 |  1200/ 3195 batches | lr 4.51 | ms/batch 39.26 | loss  1.56 | ppl     4.76\n",
      "| epoch   3 |  1400/ 3195 batches | lr 4.51 | ms/batch 39.11 | loss  1.58 | ppl     4.83\n",
      "| epoch   3 |  1600/ 3195 batches | lr 4.51 | ms/batch 39.23 | loss  1.58 | ppl     4.84\n",
      "| epoch   3 |  1800/ 3195 batches | lr 4.51 | ms/batch 39.21 | loss  1.59 | ppl     4.91\n",
      "| epoch   3 |  2000/ 3195 batches | lr 4.51 | ms/batch 39.18 | loss  1.57 | ppl     4.82\n",
      "| epoch   3 |  2200/ 3195 batches | lr 4.51 | ms/batch 39.13 | loss  1.70 | ppl     5.50\n",
      "| epoch   3 |  2400/ 3195 batches | lr 4.51 | ms/batch 39.12 | loss  1.71 | ppl     5.50\n",
      "| epoch   3 |  2600/ 3195 batches | lr 4.51 | ms/batch 39.24 | loss  1.67 | ppl     5.32\n",
      "| epoch   3 |  2800/ 3195 batches | lr 4.51 | ms/batch 39.23 | loss  1.65 | ppl     5.20\n",
      "| epoch   3 |  3000/ 3195 batches | lr 4.51 | ms/batch 39.28 | loss  1.58 | ppl     4.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 130.28s | valid loss  0.61 | valid ppl     1.84\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69XBPGH29DNl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "GF9fE5Yr2UUS",
    "outputId": "249b326e-2048-4bb7-f9ec-530567fb3512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  0.60 | test ppl     1.82\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGQF_88n2UUU"
   },
   "outputs": [],
   "source": [
    "for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eIi-zWyD9mwo",
    "outputId": "5f0dff3c-0bfe-4d76-f955-587affaba78b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 20]), torch.Size([120]))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDfNk8j49nno"
   },
   "outputs": [],
   "source": [
    "def index_to_string(indices):\n",
    "    if len(indices.shape) > 1:\n",
    "        indices = indices.view(-1)\n",
    "    return [TEXT.vocab.itos[i] for i in indices]\n",
    "\n",
    "def predict_text(model, x):\n",
    "    pred = best_model.forward(x)\n",
    "    pred = pred.view(-1, ntokens)\n",
    "    pred = pred.argmax(dim=1)\n",
    "    pred_text = index_to_string(pred)\n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhmT5ReW-qjW"
   },
   "outputs": [],
   "source": [
    "\n",
    "pred_text = predict_text(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxde4Yxy-yzU"
   },
   "outputs": [],
   "source": [
    "target_text = index_to_string(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbdRqvxA-9-z"
   },
   "outputs": [],
   "source": [
    "input_text = index_to_string(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ARKx-CP-_SQa",
    "outputId": "a28fb509-7f47-4b79-e7bd-569eb7cf61ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simmons',\n",
       " 'rapid',\n",
       " 'only',\n",
       " '.',\n",
       " 'to',\n",
       " 'for',\n",
       " 'listing',\n",
       " 'in',\n",
       " 'could',\n",
       " 'the',\n",
       " 'a',\n",
       " 'unk',\n",
       " '21',\n",
       " 'august',\n",
       " 'ensure',\n",
       " '.',\n",
       " 'polar',\n",
       " 'into',\n",
       " '<',\n",
       " '.',\n",
       " 'one',\n",
       " ';',\n",
       " 'necessary',\n",
       " '<eos>',\n",
       " 'their',\n",
       " 'a',\n",
       " 'under',\n",
       " 'a',\n",
       " 'merely',\n",
       " 'arikamedu',\n",
       " 'splendid',\n",
       " '>',\n",
       " 'entering',\n",
       " '2004',\n",
       " 'the',\n",
       " 'in',\n",
       " 'regions',\n",
       " 'the',\n",
       " 'unk',\n",
       " 'even',\n",
       " 'second',\n",
       " 'in',\n",
       " 'workers',\n",
       " ' ',\n",
       " 'limit',\n",
       " 'loss',\n",
       " 'the',\n",
       " 'spiral',\n",
       " 'be',\n",
       " 'archaeological',\n",
       " 'idea',\n",
       " 'scholar',\n",
       " 'the',\n",
       " ',',\n",
       " 'survival',\n",
       " 'the',\n",
       " 'to',\n",
       " 'entity',\n",
       " '>',\n",
       " 'when',\n",
       " 'later',\n",
       " 'particular',\n",
       " 'remained',\n",
       " 'smaller',\n",
       " ',',\n",
       " ',',\n",
       " 'planning',\n",
       " 'around',\n",
       " 'a',\n",
       " 'site',\n",
       " '\"',\n",
       " ',',\n",
       " 'fourth',\n",
       " 'carpenter',\n",
       " 'of',\n",
       " 'episode',\n",
       " 'contain',\n",
       " 'that',\n",
       " 'and',\n",
       " 'correctly',\n",
       " ',',\n",
       " ',',\n",
       " 'at',\n",
       " 'groups',\n",
       " 'and',\n",
       " 'however',\n",
       " '(',\n",
       " 'a',\n",
       " '<',\n",
       " 'was',\n",
       " '.',\n",
       " 'claimed',\n",
       " 'on',\n",
       " 'was',\n",
       " 'the',\n",
       " ',',\n",
       " 'permanently',\n",
       " 'it',\n",
       " 'walpole',\n",
       " 'prepared',\n",
       " 'stopping',\n",
       " 'there',\n",
       " 'the',\n",
       " 'included',\n",
       " 'resupply',\n",
       " ',',\n",
       " 'listed',\n",
       " 'woody',\n",
       " 'unk',\n",
       " 'by',\n",
       " 'in',\n",
       " 'in',\n",
       " 'a',\n",
       " 'set',\n",
       " 'remaining',\n",
       " 'assistant',\n",
       " 'shadowed',\n",
       " 'was',\n",
       " ',',\n",
       " ',']"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e-iXgGgpEHyt",
    "outputId": "1371509d-8e58-4359-a40e-792bf4e9eeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12075],\n",
       "        [ 2981],\n",
       "        [   78],\n",
       "        [    6],\n",
       "        [   13],\n",
       "        [   24],\n",
       "        [ 3617],\n",
       "        [   12],\n",
       "        [  158],\n",
       "        [    4],\n",
       "        [   15],\n",
       "        [   10],\n",
       "        [  517],\n",
       "        [  192],\n",
       "        [ 3424],\n",
       "        [    6],\n",
       "        [ 8377],\n",
       "        [   71],\n",
       "        [    8],\n",
       "        [    6],\n",
       "        [   49],\n",
       "        [   45],\n",
       "        [ 2029],\n",
       "        [    3],\n",
       "        [   42],\n",
       "        [   15],\n",
       "        [  139],\n",
       "        [   15],\n",
       "        [ 4457],\n",
       "        [ 6438],\n",
       "        [14907],\n",
       "        [    9],\n",
       "        [ 2502],\n",
       "        [  530],\n",
       "        [    4],\n",
       "        [   12],\n",
       "        [ 1866],\n",
       "        [    4],\n",
       "        [   10],\n",
       "        [  261],\n",
       "        [  106],\n",
       "        [   12],\n",
       "        [ 1530],\n",
       "        [   14],\n",
       "        [ 4708],\n",
       "        [  827],\n",
       "        [    4],\n",
       "        [12090],\n",
       "        [   39],\n",
       "        [ 1687],\n",
       "        [ 1007],\n",
       "        [ 3491],\n",
       "        [    4],\n",
       "        [    5],\n",
       "        [ 4934],\n",
       "        [    4],\n",
       "        [   13],\n",
       "        [ 8559],\n",
       "        [    9],\n",
       "        [   68],\n",
       "        [   83],\n",
       "        [  970],\n",
       "        [  553],\n",
       "        [  961],\n",
       "        [    5],\n",
       "        [    5],\n",
       "        [ 2163],\n",
       "        [  171],\n",
       "        [   15],\n",
       "        [  398],\n",
       "        [   17],\n",
       "        [    5],\n",
       "        [  564],\n",
       "        [ 4596],\n",
       "        [    7],\n",
       "        [  153],\n",
       "        [ 2132],\n",
       "        [   22],\n",
       "        [   11],\n",
       "        [12365],\n",
       "        [    5],\n",
       "        [    5],\n",
       "        [   32],\n",
       "        [  931],\n",
       "        [   11],\n",
       "        [  116],\n",
       "        [   28],\n",
       "        [   15],\n",
       "        [    8],\n",
       "        [   18],\n",
       "        [    6],\n",
       "        [  777],\n",
       "        [   20],\n",
       "        [   18],\n",
       "        [    4],\n",
       "        [    5],\n",
       "        [ 5416],\n",
       "        [   30],\n",
       "        [ 1448],\n",
       "        [ 2077],\n",
       "        [ 6408],\n",
       "        [   90],\n",
       "        [    4],\n",
       "        [  253],\n",
       "        [10218],\n",
       "        [    5],\n",
       "        [ 1046],\n",
       "        [ 9083],\n",
       "        [   10],\n",
       "        [   26],\n",
       "        [   12],\n",
       "        [   12],\n",
       "        [   15],\n",
       "        [  230],\n",
       "        [  907],\n",
       "        [ 2380],\n",
       "        [27876],\n",
       "        [   18],\n",
       "        [    5],\n",
       "        [    5]], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OnelNU5EbFO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer-language-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
