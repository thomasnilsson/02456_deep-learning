{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4.3-EXE-CIFAR-10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bu1Wy6Xb81Sn"
      },
      "source": [
        "# Credits\n",
        "\n",
        "This is heavily influenced from https://github.com/pytorch/tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oZW0gaQO81Sq"
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "In thins notebook you need to put what you have learned into practice, and create your own convolutional classifier for the CIFAR-10 dataset.\n",
        "\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
        "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "![cifar10](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/cifar10.png?raw=1)\n",
        "\n",
        "\n",
        "In order to train a classifier the following steps needs to be performed:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolutional Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "We will help you along the way.\n",
        "We indicate the places you need to modify the code with `# Your code here!`.\n",
        "It is however a good idea to read the entire assignment before you begin coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "htyg7xxN81St"
      },
      "source": [
        "## 1. Loading and normalizing CIFAR10\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v3u2GIWr81Su",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xx5SHRkm81S0"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1]\n",
        "\n",
        "**NB** Modify the code below to only use a small part of the dataset if your computer is very slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZeTujLC81S3",
        "outputId": "48aaa9b2-0505-43cd-a152-210a18dc8312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                          (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "used_categories = range(len(classes))\n",
        "\n",
        "## USE CODE BELOW IF YOUR COMPUTER IS TOO SLOW\n",
        "reduce_dataset = True\n",
        "if reduce_dataset:\n",
        "    used_categories = (3, 5) # cats and dogs\n",
        "\n",
        "    classes = [classes[i] for i in used_categories]\n",
        "    new_train_data = []\n",
        "    new_train_labels = []\n",
        "\n",
        "    new_test_data = []\n",
        "    new_test_labels = []\n",
        "    for i, t in enumerate(used_categories):\n",
        "        new_train_data.append(trainset.data[np.where(np.array(trainset.targets) == t)])\n",
        "        new_train_labels += [i for _ in range(new_train_data[-1].shape[0])]\n",
        "\n",
        "        new_test_data.append(testset.data[np.where(np.array(testset.targets) == t)])\n",
        "        new_test_labels += [i for _ in range(new_test_data[-1].shape[0])]\n",
        "\n",
        "    new_train_data = np.concatenate(new_train_data, 0)\n",
        "    trainset.data = new_train_data\n",
        "    trainset.targets = new_train_labels\n",
        "\n",
        "    new_test_data = np.concatenate(new_test_data, 0)\n",
        "    testset.data = new_test_data\n",
        "    testset.targets = new_test_labels\n",
        "\n",
        "\"\"\"\n",
        "## USE CODE BELOW IF YOUR COMPUTER IS TOO SLOW\n",
        "reduce_dataset = True\n",
        "if reduce_dataset:\n",
        "    used_categories = (3, 5) # cats and dogs\n",
        "\n",
        "    classes = [classes[i] for i in used_categories]\n",
        "    new_train_data = []\n",
        "    new_train_labels = []\n",
        "\n",
        "    new_test_data = []\n",
        "    new_test_labels = []\n",
        "    for i, t in enumerate(used_categories):\n",
        "        new_train_data.append(trainset.data[np.where(np.array(trainset.targets) == t)])\n",
        "        new_train_labels += [i for _ in range(new_train_data[-1].shape[0])]\n",
        "\n",
        "        new_test_data.append(testset.data[np.where(np.array(testset.targets) == t)])\n",
        "        new_test_labels += [i for _ in range(new_test_data[-1].shape[0])]\n",
        "\n",
        "    new_train_data = np.concatenate(new_train_data, 0)\n",
        "    trainset.train_data = new_train_data\n",
        "    trainset.train_labels = new_train_labels\n",
        "\n",
        "    new_test_data = np.concatenate(new_test_data, 0)\n",
        "    testset.test_data = new_test_data\n",
        "    testset.test_labels = new_test_labels\n",
        "\"\"\"\n",
        "    \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "train_data_iter = iter(trainloader)\n",
        "test_data_iter = iter(testloader)\n",
        "print('used classes:', classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 27627364.04it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "used classes: ['cat', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JDHkc52L81S9",
        "outputId": "d4e1e089-c1e4-4f5c-cbdf-fda5d770b466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import collections\n",
        "print(\"Training data\")\n",
        "print(trainset.data.shape)\n",
        "print(len(trainset.targets))\n",
        "print(collections.Counter(trainset.targets)) #Entire dataset\n",
        "print(\"Test data\")\n",
        "print(testset.data.shape)\n",
        "print(len(testset.targets))\n",
        "print()\n",
        "#print(collections.Counter(testset.test_labels)) #Only cats and dogs\n",
        "\n",
        "print(trainset.data[0])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data\n",
            "(10000, 32, 32, 3)\n",
            "10000\n",
            "Counter({0: 5000, 1: 5000})\n",
            "Test data\n",
            "(2000, 32, 32, 3)\n",
            "2000\n",
            "\n",
            "[[[125 125 116]\n",
            "  [110 101  91]\n",
            "  [102  90  83]\n",
            "  ...\n",
            "  [202 207 214]\n",
            "  [200 205 212]\n",
            "  [202 208 214]]\n",
            "\n",
            " [[142 146 142]\n",
            "  [146 144 139]\n",
            "  [176 172 170]\n",
            "  ...\n",
            "  [195 201 205]\n",
            "  [198 205 209]\n",
            "  [204 211 215]]\n",
            "\n",
            " [[180 185 183]\n",
            "  [143 146 146]\n",
            "  [156 157 157]\n",
            "  ...\n",
            "  [122 111 113]\n",
            "  [139 128 131]\n",
            "  [158 147 150]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[104  82  41]\n",
            "  [101  80  39]\n",
            "  [101  81  38]\n",
            "  ...\n",
            "  [126 103  67]\n",
            "  [126 103  69]\n",
            "  [125 101  68]]\n",
            "\n",
            " [[104  81  40]\n",
            "  [105  84  41]\n",
            "  [109  88  43]\n",
            "  ...\n",
            "  [138 113  78]\n",
            "  [137 113  80]\n",
            "  [137 112  81]]\n",
            "\n",
            " [[105  83  42]\n",
            "  [108  87  45]\n",
            "  [115  94  50]\n",
            "  ...\n",
            "  [143 117  82]\n",
            "  [143 116  84]\n",
            "  [144 116  86]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSA1h94681TB"
      },
      "source": [
        " Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "njJy0klP81TD",
        "outputId": "db5e7df7-a89f-450a-e2d9-52db845f0ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "# Run this cell multiple time to see more samples\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    \"\"\" show an image \"\"\"\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "images, labels = train_data_iter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  car plane plane plane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wt3BVFMF81TI"
      },
      "source": [
        "## 2. Define a Convolutional Neural Network\n",
        "\n",
        "**Assignment 1:** Define a convolutional neural network. \n",
        "You may use the code from previous notebooks.\n",
        "We suggest that you start with a small network, and make sure that everything is working.\n",
        "Once you can train successfully come back and improve the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9-HRotz-JS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_EsKbw3o81TK",
        "outputId": "e5210265-f0f2-40f6-89af-eaba4977ef28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "x_train=trainset.data # only cats and dogs use trainset.data \n",
        "                            # for all classes\n",
        "\n",
        "# hyperameters of the model\n",
        "num_classes = 2\n",
        "channels = x_train.shape[3] #3\n",
        "height = x_train.shape[1] #1\n",
        "width = x_train.shape[2] #2\n",
        "      #print(\"Training data\")\n",
        "      #print(trainset.data.shape)\n",
        "      #(50000, 32, 32, 3) 10000 color images 32 x 32\n",
        "num_filters_conv1 = 6 \n",
        "kernel_size_conv1 = 5 # [height, width]\n",
        "stride_conv1 = 1 # [stride_height, stride_width]\n",
        "num_filters_conv2 = 16 \n",
        "kernel_size_conv2 = 5 # [height, width]\n",
        "stride_conv2 = 1\n",
        "num_l1 = 100\n",
        "num_l2 = 10\n",
        "padding_conv1 = 2\n",
        "padding_conv2 = 2\n",
        "\n",
        "\n",
        "\n",
        "def compute_conv_dim(dim_size):\n",
        "    return int((dim_size - kernel_size_conv1 + 2 * padding_conv1) / stride_conv1 + 1)\n",
        "\n",
        "#define network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Your code here!\n",
        "        self.conv_1 = Conv2d(in_channels=channels,\n",
        "                             out_channels=num_filters_conv1,\n",
        "                             kernel_size=kernel_size_conv1,\n",
        "                             stride=stride_conv1,\n",
        "                             padding=(padding_conv1,padding_conv1))\n",
        "        \n",
        "        #self.conv_out_height = compute_conv_dim(height)\n",
        "        #self.conv_out_width = compute_conv_dim(width)\n",
        "        \n",
        "        self.maxpool1 = MaxPool2d(kernel_size=2)\n",
        "        self.dropout = Dropout2d(p=0.5)\n",
        "\n",
        "        #conv2\n",
        "        self.conv_2 = Conv2d(in_channels=num_filters_conv1,\n",
        "                             out_channels=num_filters_conv2,\n",
        "                             kernel_size=kernel_size_conv2,\n",
        "                             stride=stride_conv2,\n",
        "                             padding=(padding_conv2,padding_conv2))\n",
        "        \n",
        "        \n",
        "        \n",
        "        # add dropout to network\n",
        "        self.dropout = Dropout2d(p=0.5)\n",
        "        self.maxpool1 = MaxPool2d(kernel_size=2)\n",
        "        self.bn1=BatchNorm2d(12544)\n",
        "        \n",
        "        self.conv_out_height = compute_conv_dim(height)\n",
        "        self.conv_out_width = compute_conv_dim(width)\n",
        "        \n",
        "        #self.l1_in_features = channels * height * width\n",
        "        self.l1_in_features = num_filters_conv2 * self.conv_out_height * self.conv_out_width\n",
        "        #self.l2_in_features = num_filters_conv2 * self.conv_out_height * self.conv_out_width\n",
        "        \n",
        "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
        "                          out_features=num_l1,\n",
        "                          bias=True)\n",
        "        self.l_2 = Linear(in_features=num_l1, \n",
        "                            out_features=num_l2,\n",
        "                            bias=False)\n",
        "        \n",
        "        self.l_out = Linear(in_features=num_l2, \n",
        "                            out_features=num_classes,\n",
        "                            bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Your code here!\n",
        "        x = relu(self.conv_1(x))\n",
        "        #print(x.size()) #= [batch, channel, height, width]\n",
        "        \n",
        "        x = relu(self.conv_2(x))\n",
        "        \n",
        "        x = x.view(-1, self.l1_in_features)\n",
        "        x = relu(self.l_1(x))\n",
        "        x = torch.sigmoid(self.l_2(x))\n",
        "        \n",
        "        return torch.tanh(self.l_out(x)) #x relu(self.l_out(x), dim=1)\n",
        "    \n",
        "\n",
        "net = Net(len(used_categories))\n",
        "print(net)\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv_1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout2d(p=0.5)\n",
            "  (conv_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(12544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (l_1): Linear(in_features=16384, out_features=100, bias=True)\n",
            "  (l_2): Linear(in_features=100, out_features=10, bias=False)\n",
            "  (l_out): Linear(in_features=10, out_features=2, bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7-IUg3sq81TQ"
      },
      "source": [
        "## 3. Define a Loss function and optimizer\n",
        "\n",
        "**Assignment 2:** Implement the criterion and optimizer. \n",
        "We suggest Classification Cross-Entropy loss and SGD with momentum.\n",
        "You might need to experiment a bit with the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48AX85QP81TR",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Your code here!\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001,momentum=0.7)  # Your code here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-WneIN7C81TV"
      },
      "source": [
        "## 4. Train the network\n",
        "\n",
        "**Assignment 3:** Finish the training loop below. \n",
        "Start by using a small number of epochs (e.g. 3).\n",
        "Even with a low number of epochs you should be able to see results that are better than chance.\n",
        "When everything is working increase the number of epochs to find out how good your network really is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NkUanRRb81TW",
        "outputId": "08c75096-f63e-4090-c158-561d5754178e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "num_epoch = 15 # Your code here!\n",
        "\n",
        "\n",
        "# zero the parameter gradients\n",
        "train_acc, train_loss = [], []\n",
        "valid_acc, valid_loss = [], []\n",
        "test_acc, test_loss = [], []\n",
        "cur_loss = 0\n",
        "losses = []\n",
        "\n",
        "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
        "\n",
        "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    net.train()\n",
        "    #make minibatch\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "\n",
        "        # wrap them in Variable\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "        #print(labels)\n",
        "\n",
        "        #print(labels)\n",
        "        #print(inputs[0].shape)\n",
        "        # zero the parameter gradients\n",
        "        # Your code here!\n",
        "        #done at the begining\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # Your code here!\n",
        "        \n",
        "        output = net(inputs)\n",
        "        #print(output)\n",
        "        # compute gradients given loss\n",
        "        loss = criterion(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(loss)    \n",
        "        #cur_loss += loss   \n",
        "    #losses.append(cur_loss / batch_size)\n",
        "    \n",
        "            \n",
        "        # print statistics\n",
        "        running_loss += loss.item() #tensor.item(batch_loss[0]) #loss.data[0]\n",
        "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 1000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  1000] loss: 0.642\n",
            "[1,  2000] loss: 0.644\n",
            "[2,  1000] loss: 0.638\n",
            "[2,  2000] loss: 0.645\n",
            "[3,  1000] loss: 0.641\n",
            "[3,  2000] loss: 0.635\n",
            "[4,  1000] loss: 0.645\n",
            "[4,  2000] loss: 0.639\n",
            "[5,  1000] loss: 0.635\n",
            "[5,  2000] loss: 0.637\n",
            "[6,  1000] loss: 0.637\n",
            "[6,  2000] loss: 0.634\n",
            "[7,  1000] loss: 0.639\n",
            "[7,  2000] loss: 0.629\n",
            "[8,  1000] loss: 0.638\n",
            "[8,  2000] loss: 0.634\n",
            "[9,  1000] loss: 0.631\n",
            "[9,  2000] loss: 0.631\n",
            "[10,  1000] loss: 0.627\n",
            "[10,  2000] loss: 0.635\n",
            "[11,  1000] loss: 0.621\n",
            "[11,  2000] loss: 0.634\n",
            "[12,  1000] loss: 0.625\n",
            "[12,  2000] loss: 0.627\n",
            "[13,  1000] loss: 0.623\n",
            "[13,  2000] loss: 0.627\n",
            "[14,  1000] loss: 0.619\n",
            "[14,  2000] loss: 0.626\n",
            "[15,  1000] loss: 0.623\n",
            "[15,  2000] loss: 0.624\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0qAsbC8I81Ta"
      },
      "source": [
        "## 5. Test the network on the test data\n",
        "\n",
        "Now we need to check if the network has learnt anything at all.\n",
        "We will check this by predicting the class label that the neural network outputs, and checking it against the ground truth.\n",
        "If the prediction is correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7LT0RoAC81Tc",
        "outputId": "66ed18a9-e554-478c-87da-2a467b5eab41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "images, labels = test_data_iter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "plt.show()\n",
        "\n",
        "print('GroundTruth:  ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print('Predicted:    ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bcc0ef6dd139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imshow' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ISA6LJJO81Tg"
      },
      "source": [
        "Let us look at how the network performs on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Smv6_BwF81Ti",
        "outputId": "1984c79d-c4fa-4791-b11e-d997a726213c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
        "    testset.data.shape[0], 100 * correct / total))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 2000 test images: 65.00 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMZRvhaW81Tl"
      },
      "source": [
        "Hopefully the network is better than chance, which is $\\frac{1}{\\text{number of classes}}$ accuracy (randomly picking\n",
        "a class).\n",
        "\n",
        "\n",
        "We can also examine which class the network found the most difficult (makes more sense if you have many clases):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WqVTQgKq81Tl",
        "outputId": "47a02b69-91e4-4582-d2a3-910fd7219b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "class_total = list(0. for i in range(len(classes)))\n",
        "class_correct = list(0. for i in range(len(classes)))\n",
        "\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    \n",
        "    for i in range(len(c)):\n",
        "        label = labels[i]\n",
        "        class_correct[label] += c[i].numpy()\n",
        "        class_total[label] += 1\n",
        "print(class_total)\n",
        "for i in range(len(classes)):\n",
        "    print('Accuracy of {:5s} : {:5.2f} %'.format(\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1000.0, 1000.0]\n",
            "Accuracy of cat   : 68.30 %\n",
            "Accuracy of dog   : 63.60 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ocnQOBAl81Tn"
      },
      "source": [
        "**Assignment 4:** \n",
        "1. Go back and improve performance of the network. \n",
        " * If you are using all 10 classes you should get a test accuracy above 55%, but see how much further you can get it!\n",
        " * If you are using only 2 classes (e.g. cat and dog) you should get a test accuracy above 60%, but see how much further you can get it!\n",
        "\n",
        "2. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.\n",
        "Did anything surprise you during the exercise?\n",
        "\n",
        "3. Write down key lessons/insights you got (if any) during this exercise.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Nzefavy81To"
      },
      "source": [
        "# Training on GPU\n",
        "\n",
        "**Optional Assignment:**\n",
        "If you have a GPU we suggest that you try and rewrite the code above to run on the GPU\n",
        "___\n",
        "\n",
        "Just like how you transfer a Tensor on to the GPU, you transfer the neural net onto the GPU.\n",
        "This will recursively go over all modules and convert their parameters and buffers to CUDA tensors:\n",
        "\n",
        "```\n",
        "    net.cuda()\n",
        "```\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step to the GPU too:\n",
        "\n",
        "```\n",
        "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "```\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? \n",
        "Because your network is realllly small.\n",
        "\n",
        "**Exercise:** Try increasing the width of your network (argument 2 of\n",
        "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
        "they need to be the same number), see what kind of speedup you get.\n",
        "\n",
        "**Goals achieved**:\n",
        "\n",
        "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
        "- Train a small neural network to classify images\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8mEIylU81Tp"
      },
      "source": [
        "# Michael Nielsen book exercise of own choice\n",
        "\n",
        "**Assignment 5:** Pick an exercise of own choice from [Michael Nielsens book](http://neuralnetworksanddeeplearning.com/)\n",
        "\n",
        "One gotcha with the cross-entropy is that it can be difficult at first to remember the respective roles of the ys and the as. It's easy to get confused about whether the right form is $−[y·ln(a)+(1−y)ln(1−a)]$ or $−[a·ln(y)+(1−a)ln(1−y)]$. What happens to the second of these expressions when y=0 or 1? Does this problem afflict the first expression? Why or why not?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "When y=0 or 1 the second expression contains ln(0). The natural logarithm of 0 is undefined and $lim_{x->0} ln(x)=-\\infty$ . This problem does not occur in the first expression because the natural logarithm depends on the value of a\n",
        "\n",
        "\n"
      ]
    }
  ]
}